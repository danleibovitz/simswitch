# main function


# load libraries
library(simsurv)
library(MASS)
library(coxed)
library(data.table)
library(survival)
library(ggplot2)
library(survminer)
library(rpsftm)
library(LICORS)
library(ipcwswitch)
library(boot)
library(tidyr)
library(purrr)
library(survminer)

weihaz <- function(x, shape, scale){
  (shape/scale)*(x/scale)^(shape-1)
}


SimSwitch <- function(add_tvar, b_allowance, b_haz, b_mag, b_scale, b_shape, bcov, beta.mat, bootrep,
  cens_flag, covar_coef, dep_func, haz, hide_tvar, ipcw_robust,
  m_allowance, m_inflation, m_fidelity, m_hard, m_haz, m_mag, m_scale, m_shape,
  n, num_bvar, num_tvar, prop_cens, prop_cens_allowance, prop_cont_event, prop_switch,
  prop_trt, prop_trt_event, recens, rerun_lim, s_allowance, s_haz, s_mag, s_scale,
  s_shape, stime, switch_coef, t_allowance, t_mag, treat_hr, tse_dist, verbose, violate){


# Generating realistic survival times:
# TODO 1) implement giant while loop for adjust all 3 hazard times
    # 1.a) implement add/subtract covariates option
    # 2) add option for switching from experimental to control
    # 3) prop_event should be the proportion of total events observed by one arm, either exp or con
    # 4) b_allowance, m_allowance, b_mag

if(missing(verbose)){
  verbose <- 2
}
if(verbose > 1){
  print("Setting parameters...")
}
# set ipcw_robust. If TRUE, we skip bootstrapping for IPCW. Bootstrapped IPCW may not be symmetrical, and may be more accurate, but takes hella long
if(missing(ipcw_robust)){
  ipcw_robust <- TRUE
}

if(missing(tse_dist)){ # alternatives are weibull, lognormal, etc.
  tse_dist <- "loglogistic"
}
# set bootrep param
if(missing(bootrep)){
  bootrep <- 1000
  }
# set assumption violation flag
# TODO implement automatic assumption violation. For RPSFTM, non-constant treatment effect. For TSE, switching after secondary baseline. For IPCW, unmeasured confounding
if(missing(violate)){
  violate <- "None"
} else{
  if(!( "All" %in% violate | "None" %in% violate | all(violate %in% c("RPSFTM", "TSE", "IPCW")) )){
    stop("Violate must be set to All, None, or a subset of RPSFTM, TSE and IPCW")
  }
}

# set random censoring flag. One of no censoring, random censoring, non-random censoring
if(missing(cens_flag)){
  cens_flag <- "Random"
}else{
  if(!(cens_flag %in% c("None", "Random", "Nonrandom"))) stop("cens_flag must be one of None, Random, or Nonrandom")
  }
if(missing(prop_cens) & cens_flag != "None"){
  prop_cens <- 0.1 # default censoring proportion is 0.3 across both groups. This is pre-administrative censoring.
}
if(missing(prop_cens_allowance)){
  prop_cens_allowance <- 0.1
}
if(prop_cens < 0 | prop_cens >= 1) stop("prop_cens must be in range [0,1)")

if(missing(recens)){
  recens <- TRUE # set flag for recensoring of RPSFTM and Two-Stage Model
  }
# set dependent covariates flag
# if(missing(dep_cov)){
#   dep_cov <- TRUE # keep default FALSE while testing dependency generation
#   }

# set survival time, i.e., administrative censoring time
if(missing(stime)){
  stime <- 100
  }
if(missing(num_bvar)){
  num_bvar <- 3
}
num_bvar <- as.integer(num_bvar)
if(missing(num_tvar)){
  num_tvar <- 3
}
num_tvar <- as.integer(num_tvar)
if(num_tvar < 1) stop("Must have at least 1 time-varying covariate")
# add option for hiding relevent covariates from switching modeling
if(missing(hide_tvar)){
  hide_tvar <- 0
}
if("All" %in% violate | "IPCW" %in% violate){
  hide_tvar <- 2 # exclude 2 tvar
}
if(hide_tvar > (num_tvar-1) ) stop("can't hide more time-varying covariates than there are time-varying covariates, and time-varying cov M must always be kept.")
# add option for adding irrelevant covariates
if(missing(add_tvar)){
  add_tvar <- 0
}

# set number of participants
if(missing(n)){
  n <- 200
}
# set giant while loop flag
rerun <- TRUE
# set while loop limit
if(missing(rerun_lim)){
  rerun_lim <- 200
}
# set proportion of participants on experimental treatment
if(missing(prop_trt)){
  prop_trt <- 0.5
}
if(missing(prop_switch)){
  prop_switch <- 0.5
  }# set proportion of control participants to switch
if(missing(switch_coef)){
  switch_coef <- c(runif(num_bvar, 0.1, 0.3), runif(num_tvar, 0.3, 1)) # default of switch_coef log hazard ratios. baseline switch coefs are smaller.
}
if(length(switch_coef) != sum(num_bvar, num_tvar)) stop("the switching hazard coefficients must be of the same length as all covariates")


# Create patient id, randomization, and discrete time structure
ids <- rep(1:n, each=stime) # specify participant ids
time <- rep(1:stime, n)
id_trt <- sample(unique(ids), prop_trt*length(unique(ids))) # select participants for treatment
trt <- rep(NA, length(ids)) # create treatment covariate
trt[ids %in% id_trt] <- 1 # set treatment covariate to 1 for experimental participants
trt[is.na(trt)] <- 0
id_con <- subset(unique(ids), !(unique(ids) %in% id_trt)) # get control group ids
if(verbose > 1){
  print("Building data frames...")
}
# if(dep_cov == TRUE){ # generate covariates dependently
  xdat <- data.frame(ids = ids, arm = NA, switch = 0, time = time, treat = trt)
  xdat$arm <- ifelse(xdat$ids %in% id_trt, 1, 0)

  # TODO disease progression can be a OS * beta(a, b) and somehow dependent on baseline covars
  # set random covariates, number equal to num_bvar
  if(missing(bcov)){ # if a baseline covariate matrix is not specified, generate a random one
    bcov <- as.data.frame(abs(mvrnorm(n, rep.int(0,num_bvar), diag(0.4, num_bvar, num_bvar)))) # generate baseline covariates for each patient
  } else{
    if(dim(bcov)[1] != n | dim(bcov)[2] != num_bvar) stop("a pre-specified baseline covariate matrix must have length equal to number of patients and width equal to num_bvar")
  }
  bcov <- bcov[rep(seq_len(nrow(bcov)), each = stime), ] # repeat each row of bcov stime times
  bcov_names <- paste0(rep("b", num_bvar), seq.int(1:num_bvar)) # rename bcov columns as b1, b2, etc
  names(bcov) <- bcov_names

  # set empty tcov columns of width num_tvar
  tcov <- as.data.frame(matrix(nrow = dim(xdat[1]), ncol = num_tvar))
  tcov_names <- c("M", paste0(rep("v", num_tvar-1), seq.int(1:(num_tvar-1)))) #  rename tcov columns as M, v1, v2, etc. First name is always "M"
  names(tcov) <- tcov_names

  fulldat <- cbind(xdat, bcov, tcov) # merge covariate and treatment data
  fulldat$Mtime <- 0 # add variablre for time since beginning of M
  fulldat_cont <- fulldat # set a control group, where there is no time-dependent confounding

  # set a default covar_coef list. If user defines their own dep_func, it must call covar_coef argument even if it doesnt use it
  if(missing(covar_coef)){
    covar_coef <- list(baseline = matrix(sample(1:(num_bvar*num_tvar), num_bvar*num_tvar), ncol = num_tvar),
                       varying = matrix(sample(1:(num_tvar*(num_tvar+1)), num_tvar*(num_tvar+1)), ncol = num_tvar)) # add a coefficient row for the treatment effect
    covar_coef$baseline <- LICORS::normalize(covar_coef$baseline, byrow = FALSE)
      # sweep(covar_coef$baseline, 2, colSums(covar_coef$baseline), `/`)
    covar_coef$varying <- LICORS::normalize(covar_coef$varying, byrow = FALSE)
      # sweep(covar_coef$varying, 2, colSums(covar_coef$varying), `/`)
    covar_coef$varying[1,] <- -covar_coef$varying[1,] # make the treatment effect protective
    # TODO try to make more orderly...
    covar_coef$varying <- covar_coef$varying/200
    for(j in 1:num_tvar){
      covar_coef$varying[(j+1),j] <- 1
    }
  }

  # set dep_func (dependent function for generating covariates). must always return matrix of length fulldat, width num_tvar + 1. at least first index of num_tvar is binary
  if(missing(dep_func)){
    dep_func <- function(dat, window, base_var, time_var, covar_coef, m_haz){ # should return a binary variable for M, and continuous for all other tvar
      if(window == 1){# if window is 1, only a function of baseline.
          retval <- (as.matrix(dat[dat$time == window, names(dat) %in% base_var]) %*% covar_coef$baseline) + mvrnorm(n = sum(dat$time == window), rep.int(0,num_tvar), diag(0.05,nrow = num_tvar))
          retval[,1] <- 0 # Set initial M values to 0
          retval <- cbind(retval, rep.int(0, length(retval[,1]))) # set initial Mtimes
          return(retval)
      }else{# if window is not 1, a function of baseline, previous tvar and previous treat
        retval <- (as.matrix(dat[dat$time == (window-1), names(dat) %in% c("treat", time_var)]) %*% covar_coef$varying) + mvrnorm(n = sum(dat$time==(window-1)), rep.int(0, num_tvar), diag(0.05, nrow = num_tvar))
        # retval[,1] <- plogis(4)
        # change column of metastatic disease to binary, based upon hazard function
        retval[,1] <- ifelse(dat$M[dat$time == i-1] == 1, 1, 0) # if the previous window M is 1, continue M
        retval[retval[,1] == 0, 1] <- (rbinom( n = length(retval[, 1]), size = 1,
                                                                         prob = 1 - exp(-exp(log(m_haz[i]) +
                                                                                               as.matrix(dat[dat$time == i-1, names(dat) %in% c("treat", tcov_names)]) %*% covar_coef$varying[,1])) ))[retval[,1] == 0] # randomly assign the treat variable with probability
        retval <- cbind(retval, rep.int(0, length(retval[,1])))
        retval[,num_tvar + 1] <- ifelse(retval[,1] == 0, 0,
                                        ifelse(dat$M[dat$time == i-1] == 0, 1,
                                               dat$Mtime[dat$time == i-1]+1))
        # retval$M <- beta # replace M (metastatic disease) with a
        # fulldat$M
        return(retval)
      }
    }
  }

  # set baseline switch hazard function. lam is set as lambda of exp distribution with expected value of prop_switch by stime
  if(missing(s_haz)){
    s_haz <- weihaz(1:stime, 2, 0.7*stime)
  }
  if(!missing(s_shape) & !missing(s_scale)){
    s_haz <- weihaz(1:stime, s_shape, s_scale)
  }

  ## this section is a bit tedious. We have to set up parameters to iteratively search for the correct switching proportion
  switch_iter <- 0 # how many times have we searched?
  if(missing(s_allowance)){
    s_allowance <- 0.1
    }# how far from the proportion of switching requested is acceptable?
  s_direc <- 0 # was the last attempt too low or too high?
  prev_s_direc <- 0 # set holder variable for the previous s_direc
  if(missing(s_mag)){
    s_mag <- 0.5
  }# by what factor should we adjust the baseline hazard? must be:
  if(s_mag >= 1 | s_mag <= 0) stop("s_mag must be between 0 and 1, exclusive")

  if(missing(m_allowance)){
    m_allowance <- 0.1
  }
  m_direc <- 0
  prev_m_direc <- 0
  if(missing(m_mag)){
    m_mag <- 0.9
  }
  if(missing(m_inflation)){
    m_inflation <- 1.75
  }
  if(missing(m_fidelity)){
    m_fidelity <- 0.1
    }# represents the proportion of stime away from first M that switch can occur
  if(missing(m_hard)){
    m_hard <- FALSE
    }# represents weather switch can happen only after M, or if we don't care
  if(!(m_hard %in% c(TRUE, FALSE))) stop("m_hard must be Boolean")
  if(!missing(m_shape) & !missing(m_scale)){
    m_haz <- weihaz(1:stime, m_shape, m_scale)
  }
  if(missing(m_haz)){ # TODO if m_haz IS specified, we need to provide some other way of adjusting m_haz with respect to current_m_prop
    m_shape <- 2.8
    m_scale <- 0.7*stime
    m_haz <- weihaz(1:stime, m_shape, m_scale)
  }


  if(missing(b_haz)){
    b_haz <- weihaz(1:stime, 1, stime) # default is an exponential dist with lambda = stime
  }
  if(!missing(b_shape) & !missing(b_scale)){
    b_haz <- weihaz(1:stime, b_shape, b_scale)
  }
  if(missing(b_allowance)){
    b_allowance <- 0.1
  }
  if(missing(b_mag)){
    b_mag <- 0.5
  }
  b_direc <- 0
  prev_b_direc <- 0

  # TODO here set observed event parameters and threshhold
  if(missing(prop_trt_event)){ # if proportion of trt pts is out of window defined by b_allowance, we adjust b_haz by b_mag
    prop_trt_event <- 0.25
  }
  if(missing(prop_cont_event)){ # if proportion of control pts is out of window defined by t_allowance, we adjust treatment coefficients by t_mag
    prop_cont_event <- min(1, 1.75*prop_trt_event)
  }
  if(missing(t_allowance)){
   t_allowance <- 0.1
  }
  if(missing(t_mag)){
    t_mag <- 0.5
  }
  t_direc <- 0
  prev_t_direc <- 0

  if(verbose > 1){
    print("Setting survival coefficients...")
  }
  if(missing(treat_hr)){
    treat_hr <- -1 # default treatment coef is -1
  }
  if(missing(beta.mat)){
    beta.mat <- as.data.frame(matrix(nrow = stime, ncol = num_bvar + num_tvar + 2))
    names(beta.mat) <- c("time", "treat", bcov_names, tcov_names)
    beta.mat$time <- 1:stime
    beta.mat$treat <- treat_hr
    if(violate == "All" | "RPSFTM" %in% violate){
      beta.mat$treat <- (0.1*log(1:stime)) - 1 # make treatment effect time-dependent for violate == RPSFTM
    }
    for(j in 1:(num_bvar + num_tvar)){
      beta.mat[, j + 2] <- runif(1,0.1, 0.2) # Give non-treatment covariates exclusively small, accelerating impacts on survival
    }
    beta.mat$ids <- NA # This ONLY exists so that simsurv() doesn't complain that the betas dataframe has no 'ids' column, which is unnecessary anyhow

    # replicate beta.mat N times, for dumb reasons...
    beta.mat <- do.call("rbind", replicate(n, beta.mat, simplify = FALSE))
    beta.mat$ids <- rep(1:n, each=stime)
  }

  if(verbose > 1){
    print("Setting baseline hazard function...")
  }
  if(missing(haz)){
    haz <- function(t, x, betas, b_haz, ncov = 0, ...) {
      # exp(x[["t"]][t])*dexp(t, rate = 0.1)
      #print(exp(x[["arm"]][t]*1))
      #print( exp(last(x[["arm"]][x[["t"]] < t])*1))
      # TODO change c(5:(5+ncov)) and all similar structures to calling the actual names in names_bcov, etc.
      time <- ifelse(t > max(x[["time"]]), last(x[["time"]]), sapply( t, function(i) min(x[["time"]][x[["time"]] >= i]) ) ) # for vectorized t, get next largest values of time in discrete time sequence of x
      treatment <- x[x[["time"]] == time, c(5:(5+ncov))] # get treatment value, and all covariate values up to ncov. right now, 5 is the index of "treat"
      if(ncov != 0){ # if there are covariates apart from treatment...
        exp( rowSums(treatment*betas[time, c(2:(2+ncov))]) )*b_haz[time] # calculate exp() of linear dot product. right now, 2 is the index of "treat" in betas matrix
      }
      else{
        exp( treatment*betas[time, c(2:(2+ncov))] )*b_haz[time]
        #exp( treatment*rep.int(1,length(t)) )*b_haz[time]
      }
    }
  }

  if(verbose > 1){
    print("Filling data frames")
  }
  # TODO giant while loop should begin here. At this point, we have all parameters set, and a fulldat dataframe with no time
  # varying covariates, no switching and no secondary baseline
  while(rerun){ # iteratively update switching hazard function until we get the right proportion. The first term in this check is the number of pts whose final treatment indicator

    for(i in 1:stime){
        # set covars
        fulldat[fulldat$time == i, names(fulldat) %in% c(tcov_names, "Mtime")] <-
          dep_func(dat = fulldat, window = i, base_var=bcov_names, time_var=tcov_names, covar_coef = covar_coef, m_haz = m_haz)
        # set treatment indicator
        if(i != 1){ # if its not the first time window
          fulldat$treat[fulldat$time == i] <- ifelse(fulldat$treat[fulldat$time == i-1] == 1, 1, 0) # if the previous window treat is 1, continue treatment
        }
        # if treatment has not yet begun, probability of begining in the next window is a hazard function
        if(m_hard){
          fulldat$treat[fulldat$time == i & fulldat$treat == 0 & fulldat$Mtime > 0 & fulldat$Mtime <= ceiling(m_fidelity*stime)] <-
            rbinom( n = length(fulldat$treat[fulldat$time == i & fulldat$treat == 0 & fulldat$Mtime > 0 & fulldat$Mtime <= ceiling(m_fidelity*stime)]), size = 1,
                    prob = 1 - exp(-exp(log(s_haz[i]) +
                                          as.matrix(fulldat[fulldat$time == i & fulldat$treat == 0, names(fulldat) %in% c(bcov_names, tcov_names)]) %*% switch_coef))) # randomly assign the treat variable with probability
        }else{
          fulldat$treat[fulldat$time == i & fulldat$treat == 0] <- rbinom( n = length(fulldat$treat[fulldat$time == i & fulldat$treat == 0]), size = 1,
            prob = 1 - exp(-exp(log(s_haz[i]) +
                           as.matrix(fulldat[fulldat$time == i & fulldat$treat == 0, names(fulldat) %in% c(bcov_names, tcov_names)]) %*% switch_coef))) # randomly assign the treat variable with probability
        }

    }

  # Generate fulldat_cont (the control dataset) by blocking switching
  fulldat_cont$treat <- fulldat_cont$arm
  for(i in 1:stime){
    # set covars
    fulldat_cont[fulldat_cont$time == i, names(fulldat_cont) %in% c(tcov_names, "Mtime")] <-
      dep_func(dat = fulldat_cont, window = i, base_var=bcov_names, time_var=tcov_names, covar_coef = covar_coef, m_haz = m_haz)
  }

#  else{ # generate covariates independently. much faster.
#     id_switch <- sample(id_con, prop_switch*length(id_con)) # select participants for switch
#     # collect into dataframe
#     xdat <- data.frame(ids = ids, arm = NA, switch = NA, time = time, treat = trt)
#     xdat$arm <- ifelse(xdat$ids %in% id_trt, 1, 0)
#     xdat$switch <- ifelse(xdat$ids %in% id_switch, 1, 0)
#     # set random time stime to trt == 1
#     for(i in id_switch){
#       start <- sample(1:stime, 1)
#       xdat$treat[xdat$ids == i & xdat$time >= start] <- 1
#     }
#
#     # set random covariates, number equal to num_bvar
#     tcov <- mvrnorm(n*stime, rep.int(0,num_bvar), diag(1, num_bvar, num_bvar))
#
#     fulldat <- cbind(xdat, tcov) # merge covariate and treatment data
#     # TODO rename covars. bi for baseline covars i and vi for tvar covars i
# }


# TODO Standardize all covariates ?
############
  # fulldat[fulldat$arm == 0, names(fulldat) %in% tcov_names[tcov_names != "M"]] <- scale(fulldat[fulldat$arm == 0, names(fulldat) %in% tcov_names[tcov_names != "M"]])
  # fulldat[fulldat$arm == 1,names(fulldat) %in% tcov_names[tcov_names != "M"]] <- scale(fulldat[fulldat$arm == 1,names(fulldat) %in% tcov_names[tcov_names != "M"]])
  # fulldat_cont[fulldat_cont$arm == 0, names(fulldat_cont) %in% tcov_names[tcov_names != "M"]] <- scale(fulldat_cont[fulldat_cont$arm == 0, names(fulldat_cont) %in% tcov_names[tcov_names != "M"]])
  # fulldat_cont[fulldat_cont$arm == 1, names(fulldat_cont) %in% tcov_names[tcov_names != "M"]] <- scale(fulldat_cont[fulldat_cont$arm == 1, names(fulldat_cont) %in% tcov_names[tcov_names != "M"]])
############


######################
# Are the survival times of the confounded and unconfounded datasets probabalistically equivalent? visual inspection
  # fulldat$dat <- 0
  # fulldat_cont$dat <- 1
  # testdat <- rbind(fulldat[fulldat$arm == 1, ], fulldat_cont[fulldat_cont$arm ==1, ])
  # testdat$ids <- beta.mat$ids
  # testsdat <- simsurv( x = testdat, hazard = haz, betas = beta.mat, ncov = (num_bvar + num_tvar), maxt = 100, idvar = "ids", ids = unique(fulldat$ids),
  #                  b_haz = rep(0.01, stime))
  # testdat <- merge(testdat, testsdat, by = "ids")
  # ggsurvplot(
  #   fit = survfit(Surv(eventtime, status) ~ dat, data = testdat[testdat$time == 1,]),
  #   conf.int = TRUE)
#########################

if(verbose > 1){
  print("Generating confounded survival times...")
}
sdat <- simsurv( x = fulldat, hazard = haz, betas = beta.mat, ncov = (num_bvar + num_tvar), maxt = stime, idvar = "ids", ids = unique(fulldat$ids),
                 b_haz = b_haz)
if(verbose > 1){
  print("Generating un-confounded survival times...")
}
sdat_cont <- simsurv( x = fulldat_cont[fulldat_cont$arm == 0,], hazard = haz, betas = beta.mat[fulldat_cont$arm == 0,], ncov = (num_bvar + num_tvar), maxt = stime, idvar = "ids", ids = unique(fulldat_cont$ids[fulldat_cont$arm==0]),
                 b_haz = b_haz)
if(verbose > 1){
  print("Adding censoring...")
}
# merge datasets:
if(switch_iter == 0){ # if its the first iteration
  fulldat <- merge(fulldat, sdat, by = "ids")
  fulldat_cont <- merge(fulldat_cont, sdat_cont, by = "ids", all = TRUE)
  # replace experimental group in unconfounded dataset with experimental group in confounded dat. Theoretically, these are generated identically.
  fulldat_cont[fulldat_cont$arm == 1, ] <- fulldat[fulldat$arm == 1, ]
}else{
  fulldat <- fulldat[, !names(fulldat) %in% c("eventtime", "status")] # first remove old sdat
  fulldat <- merge(fulldat, sdat, by = "ids")

  fulldat_cont <- fulldat_cont[, !names(fulldat_cont) %in% c("eventtime", "status")] # first remove old sdat
  fulldat_cont <- merge(fulldat_cont, sdat_cont, by = "ids", all = TRUE)
  # replace experimental group in unconfounded dataset with experimental group in confounded dat. Theoretically, these are generated identically.
  fulldat_cont[fulldat_cont$arm == 1, ] <- fulldat[fulldat$arm == 1, names(fulldat) %in% names(fulldat_cont)]
}


# censor at prespecified, non-administrative censoring time. Censoring will have been generated independently of covars, or dependent on covars
if(cens_flag == "Random"){
  fulldat$cens <- stime # set default censoring time
  fulldat_cont$cens <- stime # set default censoring time

  cens_ids <- sample(unique(fulldat$ids), ceiling(prop_cens*n)) # sample prop_cens of ids for censoring
  rand_cens <- rbeta(n = length(cens_ids), shape1 = 2, shape2 = 1.5) # censoring times are drawn from a beta dist
  # rand_cens <- ceiling(rand_cens)
  rand_cens <- rep(rand_cens, each=stime) # spread to length of dataset
  fulldat$cens[fulldat$ids %in% cens_ids] <- ceiling(rand_cens*fulldat$eventtime[fulldat$ids %in% cens_ids])
  fulldat_cont$cens[fulldat_cont$ids %in% cens_ids] <- ceiling(rand_cens*fulldat_cont$eventtime[fulldat_cont$ids %in% cens_ids])

  # censor observations. Take minimum of eventtime and cens, and change status to 0 if eventtime == cens
  fulldat$eventtime <- pmin(fulldat$eventtime, fulldat$cens)
  fulldat$status <- ifelse(fulldat$eventtime == fulldat$cens, 0, fulldat$status)
  fulldat_cont$eventtime <- pmin(fulldat_cont$eventtime, fulldat_cont$cens)
  fulldat_cont$status <- ifelse(fulldat_cont$eventtime == fulldat_cont$cens, 0, fulldat_cont$status)


} else if(cens_flag == "Nonrandom"){
    # TODO nonrandom censoring function!
}


# Does the patient (control and experimental) observe secondary baseline (M)?
# TODO i think pts who observe NO M at all are being given NA here
fulldat$secbase_observed <- as.numeric(rep(sapply(unique(fulldat$ids), function(x)
  ifelse(sum(fulldat$M[fulldat$ids == x]) > 0 & fulldat$time[fulldat$Mtime == 1 & fulldat$ids == x] <= fulldat$eventtime[fulldat$Mtime == 1 & fulldat$ids == x], # id has at least some m, and time at first m is less than event time
         1,
         0)), each = stime))

# Does the patient (only control) observe switch _before eventtime_?
fulldat$switch_status <- rep(sapply(unique(fulldat$ids), function(x)
  ifelse(sum(fulldat$treat[fulldat$ids == x & fulldat$time <= fulldat$eventtime]) > 0 & fulldat$arm[fulldat$ids == x][1] == 0,
         1,
         0)), each = stime)

switch_iter <- switch_iter + 1 # iterate search indicator
if(switch_iter > rerun_lim) stop("Your covariate model failed to converge. Try different hazards and/or coefficients")

rerun <- FALSE # prempt a rerun, unless the following conditions are met

# if not enough M occurences, adjust M hazard
# TODO for now, M occurence is only being adjusted upward. do we want to give it a within-window type adjustment?
current_m_prop <- length(fulldat$ids[fulldat$arm == 0 & fulldat$Mtime == 1 & fulldat$time < fulldat$eventtime])
if(current_m_prop < min(n, prop_switch*prop_trt*n*m_inflation)){
  m_scale <- m_scale*m_mag # change scale of m related haz, and rerun
  m_haz <- weihaz(1:stime, m_shape, m_scale)
  rerun <- TRUE
}

# adjust switching proportion
current_s_prop <- sum(fulldat$switch_status[fulldat$time == 1 & fulldat$arm == 0])/length(id_con) # get current switch proportion
if(abs(current_s_prop - prop_switch) > s_allowance){ # If we're outside the window
  prev_s_direc <- s_direc # save most recent s_direc value
  s_direc <- ifelse(current_s_prop > prop_switch, -1, 1) # identify the s_direc, i.e., in what direction the baseline hazard must be adjusted
  if((prev_s_direc == -1 & s_direc == 1) | (prev_s_direc == 1 & s_direc == -1)){ # if we overshot the allowance window, and must backtrack
    s_mag <- s_mag/2 # halve switch magnitude if weve crossed over the window
  }
  s_haz <- s_haz + s_direc*s_mag*s_haz # modify the switch hazard by a factor of s_mag in the direction of s_direc
  rerun <- TRUE
}

# adjust control group event occurence
current_b_prop <- sum(fulldat$status[fulldat$time == 1 & fulldat$arm == 0])/length(id_con) # get current switch proportion
if(abs(current_b_prop - prop_cont_event) > b_allowance){ # If we're outside the window
  prev_b_direc <- b_direc # save most recent b_direc value
  b_direc <- ifelse(current_b_prop > prop_cont_event, -1, 1) # identify the s_direc, i.e., in what direction the baseline hazard must be adjusted
  if((prev_b_direc == -1 & b_direc == 1) | (prev_b_direc == 1 & b_direc == -1)){ # if we overshot the allowance window, and must backtrack
    b_mag <- b_mag/2 # halve switch magnitude if weve crossed over the window
  }
  b_haz <- b_haz + b_direc*b_mag*b_haz # modify the switch hazard by a factor of s_mag in the direction of s_direc
  rerun <- TRUE
}

# adjust trt group event occurence
current_t_prop <- sum(fulldat$status[fulldat$time == 1 & fulldat$arm == 1])/length(id_trt) # get current switch proportion
if(abs(current_t_prop - prop_trt_event) > t_allowance){ # If we're outside the window
  prev_t_direc <- t_direc # save most recent b_direc value
  t_direc <- ifelse(current_t_prop > prop_trt_event, 1, -1) # identify the t_direc, i.e., in what direction the treatment effect must be adjusted
  if((prev_t_direc == -1 & t_direc == 1) | (prev_t_direc == 1 & t_direc == -1)){ # if we overshot the allowance window, and must backtrack
    t_mag <- t_mag/2 # halve switch magnitude if weve crossed over the window
  }
  beta.mat$treat <- beta.mat$treat + t_direc*t_mag*beta.mat$treat # modify the switch hazard by a factor of s_mag in the direction of s_direc
  rerun <- TRUE
}

  }

if(verbose > 1){
  print("Performing naive method estimates...")
}
# TODO make giant loop. catch here if number of observed secbase/M, switch, or  is too low, and adjust M-hazard, switch-hazard, or b_haz (baseline hazard)
#######
    # if(observed M is too low or high){
    #   adjust M_haz
    # }
    # if(observed switch is too low or high){
    #   adjust s_haz
    # }
    # if(observed death is too low or high){
    #   adjust b_haz
    # }
#######

## Old plots
      # # plot KM curves for dependent and control datasets
      # plot(survfit(Surv(eventtime, status) ~ arm, data = fulldat[fulldat$time == stime,]), mark.time = TRUE)
      # plot(survfit(Surv(eventtime, status) ~ arm, data = fulldat_cont[fulldat_cont$time == stime,]), mark.time = TRUE)
      #
      #
      # # trtxdat <- xdat[xdat$time == 1, ]
      # # test <- cbind(trtxdat, sdat)
      # # plot(survfit(Surv(eventtime, status) ~ arm, data = test), mark.time = TRUE)
      # ggsurvplot(
      #   fit = survfit(Surv(eventtime, status) ~ arm, data = fulldat[fulldat$time == 1,]),
      #    conf.int = TRUE)
      # ggsurvplot(
      #   fit = survfit(Surv(eventtime, status) ~ arm, data = fulldat_cont[fulldat_cont$time == 1,]),
      #   conf.int = TRUE)





# Run control model (i.e., get do-treat, unconfounded estimates)
unbiased_est <- function( data, indices){ # function to pass to boot()
  d <- data[indices,] # allows boot to select sample
  fit <-   coxph(Surv(eventtime, status) ~ arm, data = d)
  return(coef(fit))
}
unbiased <- boot(data = fulldat_cont[fulldat_cont$time == 1,], statistic = unbiased_est, R = bootrep)
# Old, single rep model: coxph(Surv(eventtime, status) ~ arm, data = fulldat_cont[fulldat_cont$time == 1,])

unbiased_plot <- ggsurvplot(
  fit = survminer::surv_fit(Surv(eventtime, status) ~ arm, data = fulldat_cont[fulldat_cont$time == 1,]),
  xlab = "Time",
  ylab = "OS",
  title = "KM Plots for Unconfounded Analysis", conf.int = TRUE) %++%
  geom_hline(yintercept=0.5, linetype="dashed", size=0.1, alpha = 0.5)


# Run Naive models:

## ITT ##
# HR estimate:
itt_est <- function( data, indices){ # function to pass to boot()
  d <- data[indices,] # allows boot to select sample
  fit <-   coxph(Surv(eventtime, status) ~ arm, data = d)
  return(coef(fit))
}
itt <- boot(data = fulldat[fulldat$time == 1,], statistic = itt_est, R = bootrep)
# Old, single rep model: coxph(Surv(eventtime, status) ~ arm, data = fulldat[fulldat$time == 1,])

itt_plot <- ggsurvplot(
  fit = survminer::surv_fit(Surv(eventtime, status) ~ arm, data = fulldat[fulldat$time == 1,]),
  xlab = "Time",
  ylab = "OS",
  title = "KM Plots for ITT", conf.int = TRUE) %++%
  geom_hline(yintercept=0.5, linetype="dashed", size=0.1, alpha = 0.5)


## Per Protocol ##
# Per Protocol (censor at switch with no correction)
PPtime <- sapply(unique(fulldat$ids), function(x) stime - sum(fulldat$treat[fulldat$ids == x])) # get total time off treatment. since there is no back-switching, tihs is Per Protocol time for control patients
PPtime <- rep(PPtime, each=stime) # expand PP time
fulldat$PPtime <- ifelse(fulldat$arm == 1 | fulldat$eventtime < PPtime, fulldat$eventtime, PPtime) # if patient is in experimental group or already sees event before PPtime, use eventtime. Else censor at switch
fulldat$PPdeath <- ifelse(fulldat$PPtime < fulldat$eventtime, 0, fulldat$status) # within control group, if death had been recorded but is now censored, censor event indicator

# HR estimate
pp_est <- function(data, indices){ # function to pass to boot()
  d <- data[indices,] # allows boot to select sample
  fit <-   coxph(Surv(PPtime, PPdeath) ~ arm, data = d)
  return(coef(fit))
}
pp <- boot(data = fulldat, statistic = pp_est, R = bootrep)
# Old, single rep model: coxph(Surv(PPtime, PPdeath) ~ arm, data = fulldat)

# KM curves:
pp_plot <- ggsurvplot(
  fit = survminer::surv_fit(Surv(PPtime, PPdeath) ~ arm, data = fulldat[fulldat$time == 1, ]),
  xlab = "Time",
  ylab = "OS",
  title = "KM Plots for PP", conf.int = TRUE) %++%
  geom_hline(yintercept=0.5, linetype="dashed", size=0.1, alpha = 0.5)

# Run adjustment models:
if(verbose > 1){
  print("Performing complex method estimates: IPCW...")
}

## IPCW ##

fulldat$starttime <- fulldat$time - 1 # add starttime
fulldat$switch_time <- rep(sapply(unique(fulldat$ids), function(x) ifelse( # get first
  fulldat$arm[fulldat$ids == x][1] == 0 & fulldat$switch_status[fulldat$ids == x][1] == 1, # if id is a control pt. and observes switch,
  fulldat$time[fulldat$ids == x & fulldat$treat == 1][1], # get the first treatment time
  0)), each = stime)
fulldat$switch <- ifelse(fulldat$time == fulldat$switch_time, 1, 0)
# cut fulldat at censoring or event time. Recast several fulldat variables
fulldat_cut <- fulldat[fulldat$time < fulldat$eventtime,] # cut data past eventtime
cens_ids <- unique(fulldat_cut$ids[fulldat_cut$switch == 1]) # if you get censored, you are added to cens_ids
fulldat_cut$status[fulldat_cut$ids %in% cens_ids] <- 0 # if you get censored, your status becomes 0
fulldat_cut <- fulldat_cut[!(fulldat_cut$switch_status == 1 & fulldat_cut$switch_time < fulldat_cut$time),] # cut data from control arm switcher past the point of switch
fulldat_cut$eventstatus <- ifelse(fulldat_cut$time == floor(fulldat_cut$eventtime) & fulldat_cut$status == 1, 1, 0) # new eventstatus is 1 only if event observed before switch.
fulldat_cut$time <- as.numeric(fulldat_cut$time)
fulldat_cut$arm <- as.factor(fulldat_cut$arm)

ipform <- formula(paste("Surv(starttime, time, eventstatus) ~ arm + cluster(ids) +", paste(c(bcov_names, tcov_names), collapse = "+"), collapse = " "))

if(!ipcw_robust){
    t <- c()
    for(i in 1:10){ # TODO Cap ipcw bootrep
      bootids <- sample(unique(fulldat_cut$ids), n, replace = TRUE)
      # fit ipcw model
      ipdat <- ipcw(data = fulldat_cut[fulldat_cut$ids %in% bootids,], id = "ids", tstart = starttime,
                    tstop = time, cens = switch, arm = "arm", bas.cov = bcov_names, conf = tcov_names,
                    type = "kaplan-meier", trunc = 0.05)
      # HR estimate
      msm <- coxph(Surv(starttime, time, eventstatus) ~ arm , data = ipdat, weights = ipdat$weights.trunc)
      t[i] <- coef(msm)
    }
    # on full data
    ipdat <- ipcw(data = fulldat_cut, id = "ids", tstart = starttime,
                  tstop = time, cens = switch, arm = "arm", bas.cov = bcov_names, conf = tcov_names,
                  type = "kaplan-meier", trunc = 0.05)
    # HR estimate
    msm <- coxph(Surv(starttime, time, eventstatus) ~ arm , data = ipdat, weights = ipdat$weights.trunc)
    t0 <- coef(msm)
} else{ # use robust SE, and skip bootstrapping
  # on full data
  ipdat <- ipcw(data = fulldat_cut, id = "ids", tstart = starttime,
                tstop = time, cens = switch, arm = "arm", bas.cov = bcov_names, conf = tcov_names,
                type = "kaplan-meier", trunc = 0.05)
  # HR estimate
  msm <- coxph(Surv(starttime, time, eventstatus) ~ arm, data = ipdat, weights = ipdat$weights.trunc)
  robust_se <- sqrt(diag(msm$var))
  t <- c(coef(msm), coef(msm) - robust_se, coef(msm) + robust_se)
  t0 <- coef(msm)

}

# collect HR estimates
msm_hr <- list(t = t, t0 = t0)

# make weighted KM estimates
# TODO This doesnt work... at all
ipcw_plot <- ggsurvplot(
  fit = survminer::surv_fit(Surv(starttime, time, eventstatus) ~ arm, data = ipdat, weights = ipdat$weights.trunc),
  xlab = "Time",
  ylab = "OS",
  title = "KM Plots for IPCW", conf.int = TRUE) %++%
  geom_hline(yintercept=0.5, linetype="dashed", size=0.1, alpha = 0.5)

if(verbose > 1){
  print("Performing complex method estimates: RPSFTM...")
}
## RPSFTM ##

# get proportion of treatment per patient
# TODO should this function actually return treatment UP UNTIL eventtime, i.e., including continuous time until eventtime?
rx <- sapply(unique(fulldat$ids), function(x) sum(fulldat$treat[fulldat$ids == x & fulldat$time < fulldat$eventtime])/
               fulldat$eventtime[fulldat$ids==x & fulldat$time==1])
rpsft_dat <- cbind(fulldat[fulldat$time == 1, ], rx) # create condensed RPSFTM dataset
rpsft_dat$cens <- stime # add an administrative censoring time, which is simply stime
rpsft_dat$arm <- as.factor(rpsft_dat$arm)

# single rep mod: Build either recensored or unrecensored model
    if(recens == TRUE){
      # build rpsftm model
      mr <- rpsftm(Surv(eventtime, status) ~ rand(arm, rx), data = rpsft_dat, low_psi = -2, hi_psi = 2, censor_time = cens)
      } else{
        mr <- rpsftm(Surv(eventtime, status) ~ rand(arm, rx), data = rpsft_dat, low_psi = -2, hi_psi = 2)
        }

    # set counterfactuals with rpsftm model object:
    rpsft_dat$counterfact <- rpsft_dat$eventtime # set default counterfactual
    rpsft_dat$counterfact[rpsft_dat$arm == 0] <- mr$Sstar[rpsft_dat$arm == 0, 1] # get rpsftm counterfactual times
    rpsft_dat$cf_status <- rpsft_dat$status
    rpsft_dat$cf_status[rpsft_dat$arm == 0] <- mr$Sstar[rpsft_dat$arm == 0, 2] # get rpsftm counterfactual death/censoring

# HR estimate
rpsft_est <- function(data, indices){ # function to pass to boot()
  d <- data[indices,] # allows boot to select sample
  # Build either recensored or unrecensored model
  if(recens == TRUE){
    # build rpsftm model
    mr <- rpsftm(Surv(eventtime, status) ~ rand(arm, rx), data = d, low_psi = -3, hi_psi = 3, censor_time = cens)
  } else{
    mr <- rpsftm(Surv(eventtime, status) ~ rand(arm, rx), data = d, low_psi = -3, hi_psi = 3)
  }

  # set counterfactuals with rpsftm model object:
  d$counterfact <- d$eventtime # set default counterfactual
  d$counterfact[d$arm == 0] <- mr$Sstar[d$arm == 0, 1] # get rpsftm counterfactual times
  d$cf_status <- d$status
  d$cf_status[d$arm == 0] <- mr$Sstar[d$arm == 0, 2] # get rpsftm counterfactual death/censoring
  fit <- coxph(Surv(counterfact, cf_status) ~ arm, data = d)
  return(coef(fit))
}
rpsft <- boot(data = rpsft_dat, statistic = rpsft_est, R = bootrep ) # TODO reduce bootreps of rpsftm
# Old, single rep model: coxph(Surv(PPtime, PPdeath) ~ arm, data = fulldat)

# make KM estimates, censored
rpsft_plot <- ggsurvplot(
  fit = survminer::surv_fit(Surv(counterfact, cf_status) ~ arm, data = rpsft_dat),
  xlab = "Time",
  ylab = "OS",
  title = "KM Plots for RPSFTM", conf.int = TRUE) %++%
  geom_hline(yintercept=0.5, linetype="dashed", size=0.1, alpha = 0.5)

if(verbose > 1){
  print("Performing complex method estimates: TSE...")
}
## TSE ##

tsdat <- fulldat[fulldat$time == 1,] # Holder for wide format
tscontrol <- fulldat[fulldat$secbase_observed == 1 & fulldat$arm == 0 & fulldat$Mtime == 1,] # take subset of pts who observe M and who are in arm == 0
#tscontrol <- tscontrol[tscontrol$time < tscontrol$eventtime,] # subset again, removing pts who observe M (secondary baseline) after eventtime
tscontrol$TSsurv <- tscontrol$eventtime - tscontrol$time
tscontrol <- tscontrol[tscontrol$TSsurv > 0,] # exclude last-day-switchers

TSEform <- formula(paste("Surv(TSsurv, status) ~ switch_status +", paste(c(bcov_names, tcov_names), collapse = "+"), collapse = " "))


# TODO are we bootstrapping the wrong dataset? should it not be tsdat that gets bootstrapped, not tscontrol?
tse_est <- function(data, indices){ # function to pass to boot()
  d <- data[indices,] # allows boot to select sample

  # fit AF model
  mod <- survreg(formula = TSEform, dist = tse_dist, data = d)
  AF <- exp(coef(mod))[names(exp(coef(mod))) == "switch_status"] # get acceleration factor
  d$counterfact <- ifelse(d$switch_status == 0,
                                  d$TSsurv + d$time, # observed survival
                                  (d$TSsurv / AF) + d$time # counterfactual survival
  )

  tsdat$counterfact <- tsdat$eventtime # reset counterfactuals
  for(i in unique(d$ids)){
    tsdat$counterfact[tsdat$ids == i] <- d$counterfact[d$ids == i]
  }
  fit <- coxph(Surv(counterfact, status) ~ arm, data = tsdat)
  return(coef(fit))
}
tse_wrapper <- possibly(tse_est, otherwise = NA)
tse <- boot(data = tscontrol, statistic = tse_wrapper, R = bootrep)

#########
    # fit AF model
    mod <- survreg(formula = TSEform, dist = tse_dist, data = tscontrol)

    AF <- exp(coef(mod))[names(exp(coef(mod))) == "switch_status"] # get acceleration factor
    tscontrol$counterfact <- ifelse(tscontrol$switch_status == 0,
                                    tscontrol$TSsurv + tscontrol$time, # observed survival
                                    (tscontrol$TSsurv / AF) + tscontrol$time # counterfactual survival
    )

    tsdat$counterfact <- tsdat$eventtime # reset counterfactuals
    for(i in unique(tscontrol$ids)){
      tsdat$counterfact[tsdat$ids == i] <- tscontrol$counterfact[tscontrol$ids == i]
    }
#########

# make KM estimates, censored
tse_plot <- ggsurvplot(
  fit = survminer::surv_fit(Surv(counterfact, status) ~ arm, data = tsdat),
  xlab = "Time",
  ylab = "OS",
  title = "KM Plots for TSE", conf.int = TRUE) %++%
      geom_hline(yintercept=0.5, linetype="dashed", size=0.1, alpha = 0.5)


# TODO Recensor!

    # build boxplot dataset
    df <- data.frame(Unbiased = rep(NA, bootrep), ITT = NA, PP = NA, IPCW = NA, RPSFTM = NA, TSE = NA)
    df$Unbiased[1:length(unbiased$t)] <- unbiased$t
    df$ITT[1:length(itt$t)] <- itt$t
    df$PP[1:length(pp$t)] <- pp$t
    df$IPCW[1:length(msm_hr$t)] <-  msm_hr$t
    df$RPSFTM[1:length(rpsft$t)] <- rpsft$t
    df$TSE[1:length(tse$t)] <- tse$t
    df <- df %>% pivot_longer(names(df), names_to = "Method", values_to = "est") # df wide to long, for ggplot
    compar_plot <- ggplot(df, aes(Method, est, color = Method)) + geom_boxplot() +
      scale_color_brewer(palette = "Dark2") + theme_bw() + theme(axis.title.x=element_blank(),
                                                                 axis.text.x=element_blank(),
                                                                 axis.ticks.x=element_blank()) +
      ylab("Log HR Estimate") +
      ggtitle("Log HR Estimates Across Methods") +
      geom_hline(yintercept=unbiased$t0, linetype="dashed", size=0.1, alpha = 0.5)

    secondary_baseline_observed <- sum(fulldat$secbase_observed[fulldat$time == 1], na.rm = TRUE) / n
    switch_observed <- sum(fulldat$switch_status[fulldat$time == 1], na.rm = TRUE) / length(id_con)

    if(verbose > 1){
      print("Done!")
    }


    return(list(unbiased = unbiased, unbiased_plot = unbiased_plot, itt = itt,
                itt_plot = itt_plot, pp = pp, pp_plot = pp_plot,
                ipcw = msm_hr, ipcw_plot = ipcw_plot, rpsft = rpsft,
                rpsft_plot = rpsft_plot, tse = tse, tse_plot = tse_plot, compar_plot = compar_plot,
                params = list(bootrep = bootrep, violate = violate, cens_flag = cens_flag, prop_cens = prop_cens,
                              recens = recens, stime = stime, num_bvar = num_bvar, num_tvar = num_tvar,
                              hide_tvar = hide_tvar, add_tvar = add_tvar, n = n, rerun_lim = rerun_lim,
                              prop_trt = prop_trt, prop_switch = prop_switch, switch_coef = switch_coef, bcov = bcov,
                              covar_coef = covar_coef, s_haz = s_haz, s_allowance = s_allowance,
                              m_hard = m_hard, m_haz = m_haz, beta.mat = beta.mat, haz = haz, b_haz = b_haz,
                              secondary_baseline_observed = secondary_baseline_observed,
                              switch_observed = switch_observed,
                              iterations = switch_iter, proportion_events_control = current_b_prop,
                              proportion_events_experimental = current_t_prop,
                              proportion_switchers = current_s_prop,
                              confounded_data = fulldat,
                              unconfounded_data = fulldat_cont,
                              compar_df = df)))

}






jcar017_pseudo_t <- simswitch(
  n = 184,
  prop_trt = 0.5,
  prop_switch = 0.53,
  s_allowance = 0.1,
  prop_cens = 0.95,
  prop_cont_event = 0.2608,
  b_allowance = 0.1,
  prop_trt_event = 0.1413,
  t_allowance = 0.1,
  bootrep = 30,
  recens = FALSE,
  b_shape = 2,
  b_scale = 100,
  m_inflation = 1.75,
  m_fidelity = 0.1,
  m_hard = TRUE
)

two <- simswitch(
  n = 200,
  prop_trt = 0.5,
  prop_switch = 0.8,
  s_allowance = 0.1,
  prop_cens = 0,
  prop_cont_event = 0.7,
  b_allowance = 0.1,
  prop_trt_event = 0.3,
  t_allowance = 0.1,
  bootrep = 30,
  recens = TRUE,
  b_shape = 2,
  b_scale = 100,
  m_inflation = 1.75,
  m_fidelity = 0.2,
  m_hard = TRUE,
  unfix = "T",
  treat_hr = -1
)



# make a sequence along levels of switching
# TODO pass old params to each of next simulations
sequence <- list()
switch_i <- seq(0.05,0.50, 0.05)
for(i in 1:length(switch_i)){
  sequence[[i]] <- simswitch(
    n = 200,
    num_tvar = 5,
    num_bvar = 5,
    prop_trt = 0.5,
    prop_switch = switch_i[i],
    s_allowance = 0.1,
    prop_cens = 0.3,
    prop_cont_event = 0.3,
    b_allowance = 0.1,
    prop_trt_event = 0.2,
    t_allowance = 0.1,
    bootrep = 100,
    recens = FALSE,
    b_shape = 2,
    b_scale = 100,
    m_inflation = 1.75,
    m_fidelity = 0.1,
    m_hard = TRUE
  )
}

for(j in 1:length(sequence)){
  #print(sequence[[j]]$params$switch_observed)
  sequence[[j]]$params$compar_df$switch <- switch_i[j]
}

df <- sequence[[1]]$params$compar_df
df$est <- exp(df$est)
df$est[df$Method != "Unbiased"] <- df$est[df$Method != "Unbiased"] - mean(df$est[df$Method == "Unbiased"])
for(j in 2:length(sequence)){
  f <- sequence[[j]]$params$compar_df
  f$est <- exp(f$est)
  f$est[f$Method != "Unbiased"] <- f$est[f$Method != "Unbiased"] - mean(f$est[f$Method == "Unbiased"])
  df <- rbind(df, f)
}

# TODO transform from Log HR back to HR
df6 <- sequence[[5]]$params$compar_df
df6$est <- exp(df6$est)
df6$est[df6$Method != "Unbiased"] <- df6$est[df6$Method != "Unbiased"] - mean(df6$est[df6$Method == "Unbiased"])

ggplot(df[df$Method != "Unbiased",], aes(x=switch, y=est, color=Method, fill=Method)) +
  #geom_errorbar()
  stat_summary(fun.y = mean, geom="line") +
  #geom_smooth(method = loess, alpha=0.15) +
  scale_color_brewer(palette = "Dark2") + theme_bw() +
  scale_fill_brewer(palette = "Dark2") +
  ggtitle("(B) HR Estimate Bias for Parameter Range") +
  xlab("Proportion of Switchers in Control Arm") +
  ylab("HR Estimate Bias") +
  geom_hline(yintercept=0, linetype="dashed", size=0.1, alpha = 0.5)

#sequence[[6]]$compar_plot +
#  ggtitle("(A) Log HR Estimates Across Methods")

ggplot(df6[df6$Method != "Unbiased",], aes(Method, est, color = Method)) + geom_boxplot(outlier.shape = NA) +
  scale_color_brewer(palette = "Dark2") + theme_bw() + theme(axis.title.x=element_blank(),
                                                             axis.text.x=element_blank(),
                                                             axis.ticks.x=element_blank()) +
  ylab("HR Estimate Bias") +
  ggtitle("HR Estimate Bias Across Methods") +
  ylim(c(-0.3,1)) +
  geom_hline(yintercept=0, linetype="dashed", size=0.1, alpha = 0.5)


sequence <- list()
switch_i <- seq(0.1,0.90, 0.1)
for(i in 2:length(switch_i)){
  sequence[[i]] <- simswitch(
    n = sequence[[i-1]]$params$n,
    num_tvar = sequence[[i-1]]$params$num_tvar,
    num_bvar = sequence[[i-1]]$params$num_bvar,
    prop_trt = sequence[[i-1]]$params$prop_trt,
    prop_switch = switch_i[[i]],
    s_allowance = 0.025,
    prop_cens = sequence[[i-1]]$params$prop_cens,
    prop_cont_event = sequence[[i-1]]$params$prop_cont_event,
    b_allowance = 0.1,
    prop_trt_event = sequence[[i-1]]$params$prop_trt,
    t_allowance = 0.1,
    bootrep = sequence[[i-1]]$params$bootrep,
    recens = sequence[[i-1]]$params$recens,
    b_haz = sequence[[i-1]]$params$b_haz,
    m_inflation = sequence[[i-1]]$params$m_inflation,
    m_fidelity = sequence[[i-1]]$params$m_fidelity,
    m_hard = FALSE,
    unfix = c("B", "M", "T"),
    bcov = sequence[[i-1]]$params$bcov,
    beta.mat = sequence[[i-1]]$params$beta.mat,
    covar_coef = sequence[[i-1]]$params$covar_coef,
    # dep_func = sequence[[i-1]]$params$dep_func,
    # haz = sequence[[i-1]]$params$haz(),
    # ipcw_robust = sequence[[i-1]]$params$ipcw_robust,
    m_haz = sequence[[i-1]]$params$m_haz,
    s_haz = sequence[[i-1]]$params$s_haz,
    # tse_dist = sequence[[i-1]]$params$tse_dist,
    add_tvar = sequence[[i-1]]$params$add_tvar,
    hide_tvar = sequence[[i-1]]$params$hide_tvar,
    # m_allowance = sequence[[i-1]]$params$m_allowance,
    # prop_cens_allowance = sequence[[i-1]]$params$prop_cens_allowance,
    rerun_lim = sequence[[i-1]]$params$rerun_lim,
    stime = sequence[[i-1]]$params$stime,
    switch_coef = sequence[[i-1]]$params$switch_coef
  )
}



# TODO WTF is wrong with the IPCW? Why is it ALWAYS so biased? Is it coded wrong, or are we violating assumptions?
# TODO simulate with M_soft and go all the way to 80%
# TODO simulate backswitching from experimental to control group
# TODO maybe simsurv can be made simpler and faster, if we dont use the "hazard" argument but rather the "dist" argument. definitely can.
  # TODO this will work if we only allow the exponential dist, due to its constant hazard. we can multiply the hazard by b_mag and pass the result as the param
  # for the exp() distribution
# TODO explain why we use simsurv as opposed to, e.g., simulat() from mlt package. The reason is, simsurv takes user-specified hazards
# TODO give clustering example, where one baseline cov is, e.g., a clinic clustering factor
